{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Using Adjacency Matrices to Enhance Large Language Models for Graph Reasoning Tasks\n",
        "\n",
        "by Meher Banik, Rupali Batta, and Madeline Eagan"
      ],
      "metadata": {
        "id": "_-TtzffsPcU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating the Dataset\n",
        "\n",
        "We will be prompting Chat 3.5 with our own graphs that we generated, with various encodings: Texting, Commute, Citations, and Adjacency. Additionally, for each encoding type, a corresponding adjacency matrix generator is provided. The point is to generate graphs of different encodings but also have a way of having a consistent and general form to represent such graphs."
      ],
      "metadata": {
        "id": "d661la5FPvYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Texting:"
      ],
      "metadata": {
        "id": "ePCo3RCvHc80"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaEA6M6iPKby"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "names_bank = [\"Alice\", \"Bob\", \"Charles\", \"Diana\", \"Edward\", \"Fiona\", \"George\", \"Helen\"]\n",
        "\n",
        "def create_texting_graph():\n",
        "    num_nodes = random.randint(4, 8)\n",
        "    nodes = random.sample(names_bank, num_nodes)\n",
        "    connections = []\n",
        "    for sender in nodes:\n",
        "        for receiver in nodes:\n",
        "            if sender != receiver:\n",
        "                weight = random.randint(0, 500)\n",
        "                if weight > 0:\n",
        "                    connections.append((sender, receiver, weight))\n",
        "\n",
        "    num_zero_weight = len(connections) // 4\n",
        "    zero_weight_edges = random.sample(connections, num_zero_weight)\n",
        "    for i in range(len(connections)):\n",
        "        if connections[i] in zero_weight_edges:\n",
        "            sender, receiver, _ = connections[i]\n",
        "            connections[i] = (sender, receiver, 0)\n",
        "\n",
        "    final_connections =  [f\"{sender} sent {receiver} {weight} texts.\" for sender, receiver, weight in connections]\n",
        "    random.shuffle(final_connections)\n",
        "    return final_connections\n",
        "\n",
        "graph_1 = create_texting_graph()\n",
        "graph_1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_texts_to_matrix(texts):\n",
        "    import numpy as np\n",
        "\n",
        "    interactions = {}\n",
        "    for text in texts:\n",
        "        parts = text.split()\n",
        "        sender, receiver, weight = parts[0], parts[2], int(parts[3])\n",
        "\n",
        "        if sender not in interactions:\n",
        "            interactions[sender] = {}\n",
        "        interactions[sender][receiver] = weight\n",
        "\n",
        "    names = list(set([name for text in texts for name in [text.split()[0], text.split()[2]]]))\n",
        "    names.sort()\n",
        "\n",
        "    index_map = {name: idx for idx, name in enumerate(names)}\n",
        "\n",
        "    n = len(names)\n",
        "    matrix = np.zeros((n, n), dtype=int)\n",
        "\n",
        "    for sender, receivers in interactions.items():\n",
        "        for receiver, weight in receivers.items():\n",
        "            sender_idx = index_map[sender]\n",
        "            receiver_idx = index_map[receiver]\n",
        "            matrix[sender_idx, receiver_idx] = weight\n",
        "\n",
        "    return matrix, names\n",
        "\n",
        "matrix, names = parse_texts_to_matrix(graph_1)\n",
        "\n",
        "print(\"Names Index:\", names)\n",
        "print(\"Adjacency Matrix:\\n\", matrix)"
      ],
      "metadata": {
        "id": "ybLISCOJH94e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Commute:"
      ],
      "metadata": {
        "id": "sBC03Z2MIBl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "cities_bank = [\n",
        "    \"NYC\", \"LA\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\",\n",
        "    \"Portland\", \"Raleigh\", \"Dallas\", \"Cupertino\", \"Austin\", \"Jacksonville\",\n",
        "    \"Atlanta\", \"Columbus\", \"Charlotte\", \"Miami\", \"Indianapolis\",\n",
        "    \"Seattle\", \"Denver\", \"D.C.\"\n",
        "]\n",
        "\n",
        "\n",
        "def create_texting_graph():\n",
        "    num_nodes = random.randint(4, 8)\n",
        "    nodes = random.sample(cities_bank, num_nodes)\n",
        "    connections = []\n",
        "    for sender in nodes:\n",
        "        for receiver in nodes:\n",
        "            if sender != receiver:\n",
        "                weight = random.randint(0, 500)\n",
        "                if weight > 0:\n",
        "                    connections.append((sender, receiver, weight))\n",
        "\n",
        "    num_zero_weight = len(connections) // 3\n",
        "    zero_weight_edges = random.sample(connections, num_zero_weight)\n",
        "    for i in range(len(connections)):\n",
        "        if connections[i] in zero_weight_edges:\n",
        "            sender, receiver, _ = connections[i]\n",
        "            connections[i] = (sender, receiver, 0)\n",
        "    final_connections = []\n",
        "    for sender, receiver, weight in connections:\n",
        "      if weight == 0:\n",
        "        final_connection = f\"Flying from {sender} to {receiver} takes {weight} minutes because this flight is currently unavailable.\"\n",
        "      else:\n",
        "        final_connection = f\"Flying from {sender} to {receiver} takes {weight} minutes.\"\n",
        "      final_connections.append(final_connection)\n",
        "\n",
        "    random.shuffle(final_connections)\n",
        "\n",
        "    return final_connections\n",
        "\n",
        "graph_1 = create_texting_graph()\n",
        "graph_1"
      ],
      "metadata": {
        "id": "Po69nYl8IEp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_texts_to_matrix(texts):\n",
        "    import numpy as np\n",
        "\n",
        "    interactions = {}\n",
        "    for text in texts:\n",
        "        parts = text.split()\n",
        "        sender, receiver, weight = parts[2], parts[4], int(parts[6])\n",
        "\n",
        "        if sender not in interactions:\n",
        "            interactions[sender] = {}\n",
        "        interactions[sender][receiver] = weight\n",
        "\n",
        "    names = list(set([name for text in texts for name in [text.split()[2], text.split()[4]]]))\n",
        "    names.sort()\n",
        "\n",
        "    index_map = {name: idx for idx, name in enumerate(names)}\n",
        "\n",
        "    n = len(names)\n",
        "    matrix = np.zeros((n, n), dtype=int)\n",
        "\n",
        "    for sender, receivers in interactions.items():\n",
        "        for receiver, weight in receivers.items():\n",
        "            sender_idx = index_map[sender]\n",
        "            receiver_idx = index_map[receiver]\n",
        "            matrix[sender_idx, receiver_idx] = weight\n",
        "\n",
        "    return matrix, names\n",
        "\n",
        "matrix, names = parse_texts_to_matrix(graph_1)\n",
        "\n",
        "print(\"Names Index:\", names)\n",
        "print(\"Adjacency Matrix:\\n\", matrix)"
      ],
      "metadata": {
        "id": "3bg-vs-OIKdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Citation:"
      ],
      "metadata": {
        "id": "c-5irAEpI0CA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "names_bank = [\n",
        "    \"Smith\", \"Garcia\", \"Patel\", \"Lee\", \"Brown\", \"Jones\",\n",
        "    \"Kim\", \"Nguyen\", \"Khan\", \"Martinez\", \"Chen\", \"Silva\",\n",
        "    \"Mohamed\", \"Johnson\", \"Rodriguez\", \"Ali\", \"Singh\",\n",
        "    \"Kumar\", \"Williams\", \"Yue\"\n",
        "]\n",
        "\n",
        "def create_texting_graph():\n",
        "    num_nodes = random.randint(4, 8)\n",
        "    nodes = random.sample(names_bank, num_nodes)\n",
        "    connections = []\n",
        "    for sender in nodes:\n",
        "        for receiver in nodes:\n",
        "            if sender != receiver:\n",
        "                weight = random.randint(0, 500)\n",
        "                if weight > 0:\n",
        "                    connections.append((sender, receiver, weight))\n",
        "\n",
        "    num_zero_weight = len(connections) // 3\n",
        "    zero_weight_edges = random.sample(connections, num_zero_weight)\n",
        "    for i in range(len(connections)):\n",
        "        if connections[i] in zero_weight_edges:\n",
        "            sender, receiver, _ = connections[i]\n",
        "            connections[i] = (sender, receiver, 0)\n",
        "\n",
        "    final_connections =  [f\"Dr. {sender} cited {weight} of Dr. {receiver}'s scientific papers.\" for sender, receiver, weight in connections]\n",
        "    random.shuffle(final_connections)\n",
        "    return final_connections\n",
        "\n",
        "graph_1 = create_texting_graph()\n",
        "graph_1"
      ],
      "metadata": {
        "id": "PxYv2Qh2I3Rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_texts_to_matrix(texts):\n",
        "    import numpy as np\n",
        "\n",
        "    interactions = {}\n",
        "    for text in texts:\n",
        "        parts = text.split()\n",
        "        sender, receiver, weight = parts[1], parts[6][:-2], int(parts[3])\n",
        "\n",
        "        if sender not in interactions:\n",
        "            interactions[sender] = {}\n",
        "        interactions[sender][receiver] = weight\n",
        "\n",
        "    names = list(set([name for text in texts for name in [text.split()[1], (text.split()[6])[:-2]]]))\n",
        "    names.sort()\n",
        "\n",
        "    index_map = {name: idx for idx, name in enumerate(names)}\n",
        "\n",
        "    n = len(names)\n",
        "    matrix = np.zeros((n, n), dtype=int)\n",
        "\n",
        "    for sender, receivers in interactions.items():\n",
        "        for receiver, weight in receivers.items():\n",
        "            sender_idx = index_map[sender]\n",
        "            receiver_idx = index_map[receiver]\n",
        "            matrix[sender_idx, receiver_idx] = weight\n",
        "\n",
        "    return matrix, names\n",
        "\n",
        "matrix, names = parse_texts_to_matrix(graph_1)\n",
        "\n",
        "print(\"Names Index:\", names)\n",
        "print(\"Adjacency Matrix:\\n\", matrix)"
      ],
      "metadata": {
        "id": "tpV5o7wIJXMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adjacency:"
      ],
      "metadata": {
        "id": "BAmz-xIKJjkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def create_adjacency_graph():\n",
        "    num_nodes = random.randint(4, 8)\n",
        "\n",
        "    possible_edges = [(i, j) for i in range(num_nodes) for j in range(num_nodes) if i != j]\n",
        "\n",
        "    num_edges = random.randint(1, len(possible_edges))\n",
        "\n",
        "    random_edges = random.sample(possible_edges, num_edges)\n",
        "\n",
        "    weighted_edges = [(edge[0], edge[1], random.randint(1, 100)) for edge in random_edges]\n",
        "    for i in range(int(len(weighted_edges) / 3)):\n",
        "        edge_to_zero = random.choice(weighted_edges)\n",
        "        weighted_edges[weighted_edges.index(edge_to_zero)] = (edge_to_zero[0], edge_to_zero[1], 0)\n",
        "\n",
        "    graph_description = f\"In a directed graph, (i, j, w) means that node i and node j are connected with a directed edge from i to j with weight w. G describes a graph among nodes {', '.join(map(str, range(num_nodes)))}. The edges in G are: \"\n",
        "    graph_description += \" \".join(f\"({edge[0]}, {edge[1]}, {edge[2]})\" for edge in weighted_edges) + \".\"\n",
        "\n",
        "    return graph_description\n",
        "\n",
        "graph_a_1 = create_adjacency_graph()\n",
        "\n",
        "print(graph_a_1)"
      ],
      "metadata": {
        "id": "scE7rcdrJnqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "def parse_graph_description(description):\n",
        "    descriptions = description.split('.\\n')\n",
        "    all_graphs = []\n",
        "\n",
        "    for desc in descriptions:\n",
        "        if 'nodes' in desc and 'edges' in desc:\n",
        "            nodes_part = re.search(r'nodes ([0-9, ]+)\\.', desc)\n",
        "            nodes = list(map(int, nodes_part.group(1).split(', ')))\n",
        "\n",
        "            edges_part = re.findall(r'\\(\\d+, \\d+, \\d+\\)', desc)\n",
        "            edges = [tuple(map(int, edge.strip('()').split(', '))) for edge in edges_part]\n",
        "\n",
        "            all_graphs.append((nodes, edges))\n",
        "\n",
        "    return all_graphs\n",
        "\n",
        "\n",
        "def create_adjacency_matrix(nodes, edges):\n",
        "    size = len(nodes)\n",
        "    matrix = np.zeros((size, size), dtype=int)\n",
        "\n",
        "    for edge in edges:\n",
        "        i, j, weight = edge\n",
        "        matrix[i][j] = weight # ROW -> COLUMN\n",
        "\n",
        "    return matrix\n",
        "\n",
        "def print_adjacency_matrix(matrix):\n",
        "    print('\\n'.join(' '.join(str(cell) for cell in row) for row in matrix))\n",
        "\n",
        "graphs = parse_graph_description(graph_a_1)\n",
        "\n",
        "for nodes, edges in graphs:\n",
        "    print(f\"Graph with nodes: {nodes} and edges: {edges}\")\n",
        "    adjacency_matrix = create_adjacency_matrix(nodes, edges)\n",
        "    print_adjacency_matrix(adjacency_matrix)\n",
        "    print()"
      ],
      "metadata": {
        "id": "TxeitEj4JtX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once these graph generation methods were written, 10 graphs were generated for each type of encoding, resulting in 40 in total. Such graphs were numbered 1-40 and added to a spreadsheet. For each graph, the original encoding representation was included under the \"Graph for LLM\" column, the adjacency matrix and corresponding name bank was included the \"Adjacency Matrix\" column, and the Graph Task QA column was left blank for the moment, which will be generated in the next step."
      ],
      "metadata": {
        "id": "HCh9-u-3JxxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Task QA Algorithms"
      ],
      "metadata": {
        "id": "01LKt_88Kooa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, 10 algorithms were written in python that aimed to answer the 10 Graph Tasks that were initially established:\n",
        "\n",
        "Edge existence. Determine whether a given edge exists in a graph.\n",
        "\n",
        "Node degree. Calculate the degree of a given node in a graph.\n",
        "\n",
        "Node count. Count the number of nodes in a graph.\n",
        "\n",
        "Edge count. Count the number of edges in a graph.\n",
        "\n",
        "Connected nodes. Find all the nodes that are connected to a given node in a graph.\n",
        "\n",
        "Cycle check. Determine whether a graph contains a cycle.\n",
        "\n",
        "Disconnected nodes. Find all the nodes that are not connected to a given node in a graph.\n",
        "\n",
        "Reachability. Determine whether there is a path from one node to another.\n",
        "\n",
        "Shortest path. Calculate the length of the shortest path from one node to another.\n",
        "\n",
        "Weakly Connected. Determine whether a graph is weakly connected."
      ],
      "metadata": {
        "id": "H9--SGXBLU6J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Processing\n",
        "\n",
        "Thhis method helps us convert our adjacency matrices that we generated in the Graph Generation Colab into a consistent format so that the algorithms can take in any graph we input, regardless of orginal decoding format. This makes for a more streamlined pipeline when trying to obtain our values for each question for a respective graph."
      ],
      "metadata": {
        "id": "VNNRei_rLwne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_string = \"\"\" \"\"\" #FILL IN ADJACENCY MATRIX OUTPUT FROM PREVIOUS COLAB\n",
        "name_bank =  None #FILL IN WITH CORRESPONDING NAME BANK FROM PREVIOUS COLAB\n",
        "\n",
        "answers = [None] * 10 # Keeps track of our answers for each graph task question\n",
        "\n",
        "def parse_matrix(matrix_string):\n",
        "    lines = matrix_string.strip().split('\\n')\n",
        "\n",
        "    matrix = []\n",
        "    for line in lines:\n",
        "        line = line.strip().replace('[', '').replace(']', '')\n",
        "        row = list(map(int, line.split()))\n",
        "        matrix.append(row)\n",
        "\n",
        "    return matrix\n",
        "\n",
        "matrix = parse_matrix(matrix_string)\n",
        "print(matrix)"
      ],
      "metadata": {
        "id": "fRXM96JbLvZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Methods\n",
        "\n",
        "We run all of these methods on each graph in order to obtain an \"answer key\" of sorts. We have verified this code returns the correct values for specific edge cases and on various graphs in order to ensure the answers we generate are accurate. We generate such a key to gauge LLM performance."
      ],
      "metadata": {
        "id": "Zk4rGQ3ML_aY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Edge Existence"
      ],
      "metadata": {
        "id": "EqvOAx6eMGXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_exists(matrix, name_bank, u, v):\n",
        "    if u not in name_bank or v not in name_bank:\n",
        "        return False\n",
        "    u_index = name_bank.index(u)\n",
        "    v_index = name_bank.index(v)\n",
        "    return matrix[u_index][v_index] > 0\n",
        "\n",
        "name1 = name_bank[0]\n",
        "name2 = name_bank[2]\n",
        "\n",
        "v1 = edge_exists(matrix, name_bank, name1, name2)\n",
        "v2 = edge_exists(matrix, name_bank, name2, name1)\n",
        "\n",
        "answers[0] = (v1, v2)"
      ],
      "metadata": {
        "id": "EYzMANB8MFrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2a. Node-In Degree\n"
      ],
      "metadata": {
        "id": "rQCEsy5HMKIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def in_degree(matrix, name_bank, node):\n",
        "    index = name_bank.index(node)\n",
        "    in_degree_count = sum(1 for row in matrix if row[index] > 0)\n",
        "    return in_degree_count\n",
        "\n",
        "name1 = name_bank[3]\n",
        "v1 = in_degree(matrix, name_bank, name1)"
      ],
      "metadata": {
        "id": "u-8ups-BMMxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2b. Node-Out Degree"
      ],
      "metadata": {
        "id": "V7z0LUDAMNs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def out_degree(matrix, name_bank, node):\n",
        "    index = name_bank.index(node)\n",
        "    out_degree_count = sum(1 for weight in matrix[index] if weight > 0)\n",
        "    return out_degree_count\n",
        "\n",
        "name1 = name_bank[3]\n",
        "v2 = out_degree(matrix, name_bank, name1)\n",
        "\n",
        "answers[1] = (v1, v2)"
      ],
      "metadata": {
        "id": "dguo4F0TMRHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Node Count"
      ],
      "metadata": {
        "id": "g5RmBKBDMT0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def node_count(matrix):\n",
        "    return len(matrix)\n",
        "\n",
        "answers[2] = node_count(matrix)"
      ],
      "metadata": {
        "id": "sy4eL0MzMTb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Edge Count"
      ],
      "metadata": {
        "id": "zKdK6nZ8MYIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_count(matrix):\n",
        "    return sum(sum(1 for weight in row if weight > 0) for row in matrix)\n",
        "\n",
        "answers[3] = (edge_count(matrix))"
      ],
      "metadata": {
        "id": "u8ZNBDITMWLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Connected Nodes"
      ],
      "metadata": {
        "id": "lgSBJn4bMchD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def connected_nodes(matrix, name_bank, node):\n",
        "    index = name_bank.index(node)\n",
        "    return [name_bank[i] for i, weight in enumerate(matrix[index]) if weight > 0]\n",
        "\n",
        "name1 = name_bank[2]\n",
        "\n",
        "answers[4] = connected_nodes(matrix, name_bank, name1)"
      ],
      "metadata": {
        "id": "OISYGB9qMcSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Cycle Detection"
      ],
      "metadata": {
        "id": "JXqyN7BLMhId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def has_cycle(matrix):\n",
        "    num_nodes = len(matrix)\n",
        "    visited = [False] * num_nodes\n",
        "    rec_stack = [False] * num_nodes\n",
        "\n",
        "    def cycle_util(v):\n",
        "        visited[v] = True\n",
        "        rec_stack[v] = True\n",
        "        for i in range(num_nodes):\n",
        "            if matrix[v][i] > 0:\n",
        "                if not visited[i]:\n",
        "                    if cycle_util(i):\n",
        "                        return True\n",
        "                elif rec_stack[i]:\n",
        "                    return True\n",
        "        rec_stack[v] = False\n",
        "        return False\n",
        "\n",
        "    for node in range(num_nodes):\n",
        "        if not visited[node]:\n",
        "            if cycle_util(node):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "answers[5] = has_cycle(matrix)"
      ],
      "metadata": {
        "id": "uP8LsRrqMgPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Disconnected Nodes"
      ],
      "metadata": {
        "id": "kVjudIjrMl7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def disconnected_nodes(matrix, name_bank, node):\n",
        "    index = name_bank.index(node)\n",
        "    reachable = set()\n",
        "\n",
        "    def dfs(v):\n",
        "        for i in range(len(matrix)):\n",
        "            if matrix[v][i] > 0 and i not in reachable:\n",
        "                reachable.add(i)\n",
        "                dfs(i)\n",
        "\n",
        "    reachable.add(index)\n",
        "    dfs(index)\n",
        "    return [name_bank[i] for i in range(len(matrix)) if i not in reachable]\n",
        "\n",
        "name1 = name_bank[3]\n",
        "\n",
        "answers[7] = disconnected_nodes(matrix, name_bank, name1)"
      ],
      "metadata": {
        "id": "rTtVZTo2Mlvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Reachability"
      ],
      "metadata": {
        "id": "1CXO58qOMsb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_reachable(matrix, name_bank, start, end):\n",
        "    start_index = name_bank.index(start)\n",
        "    end_index = name_bank.index(end)\n",
        "    visited = [False] * len(matrix)\n",
        "    stack = [start_index]\n",
        "\n",
        "    while stack:\n",
        "        node = stack.pop()\n",
        "        if node == end_index:\n",
        "            return True\n",
        "        if not visited[node]:\n",
        "            visited[node] = True\n",
        "            for i in range(len(matrix)):\n",
        "                if matrix[node][i] > 0 and not visited[i]:\n",
        "                    stack.append(i)\n",
        "    return False\n",
        "\n",
        "name1 = name_bank[0]\n",
        "name2 = name_bank[2]\n",
        "\n",
        "v1 = is_reachable(matrix, name_bank, name1, name2)\n",
        "v2 = is_reachable(matrix, name_bank, name2, name1)\n",
        "\n",
        "answers[7] = (v1, v2)"
      ],
      "metadata": {
        "id": "_ujwDE-gMuRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Shortest Path"
      ],
      "metadata": {
        "id": "mTID7WwqMv9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "def shortest_path(matrix, name_bank, start, end):\n",
        "    start_index = name_bank.index(start)\n",
        "    end_index = name_bank.index(end)\n",
        "    queue = deque([(start_index, 0)])\n",
        "    visited = [False] * len(matrix)\n",
        "\n",
        "    while queue:\n",
        "        node, distance = queue.popleft()\n",
        "        if node == end_index:\n",
        "            return distance\n",
        "        if not visited[node]:\n",
        "            visited[node] = True\n",
        "            for i in range(len(matrix)):\n",
        "                if matrix[node][i] > 0 and not visited[i]:\n",
        "                    queue.append((i, distance + 1))\n",
        "    return float('inf')  # or None if no path exists\n",
        "\n",
        "name1 = name_bank[1]\n",
        "name2 = name_bank[3]\n",
        "\n",
        "v1 = shortest_path(matrix, name_bank, name1, name2)\n",
        "v2 = shortest_path(matrix, name_bank, name2, name1)\n",
        "\n",
        "answers[8] = (v1, v2)"
      ],
      "metadata": {
        "id": "lS7GoaW1Mx-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Weakly Connected"
      ],
      "metadata": {
        "id": "B4RQgpUEM2H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import deque\n",
        "\n",
        "def is_weakly_connected(matrix, name_bank):\n",
        "    n = len(matrix)\n",
        "\n",
        "    undirected_matrix = [[0] * n for _ in range(n)]\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if matrix[i][j] > 0 or matrix[j][i] > 0:\n",
        "                undirected_matrix[i][j] = 1\n",
        "                undirected_matrix[j][i] = 1\n",
        "\n",
        "    def bfs(start):\n",
        "        visited = [False] * n\n",
        "        queue = deque([start])\n",
        "        visited[start] = True\n",
        "\n",
        "        while queue:\n",
        "            node = queue.popleft()\n",
        "            for neighbor in range(n):\n",
        "                if undirected_matrix[node][neighbor] > 0 and not visited[neighbor]:\n",
        "                    visited[neighbor] = True\n",
        "                    queue.append(neighbor)\n",
        "\n",
        "        return visited\n",
        "\n",
        "    visited_nodes = bfs(0)\n",
        "\n",
        "    return all(visited_nodes)\n",
        "\n",
        "answers[9] = is_weakly_connected(matrix, name_bank)"
      ],
      "metadata": {
        "id": "1vmnpb6GM5Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Answers:"
      ],
      "metadata": {
        "id": "crQ4NQOPM8fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = 1\n",
        "for answer in answers:\n",
        "  print(str(index) + \". \"+ str(answer))\n",
        "  index += 1"
      ],
      "metadata": {
        "id": "iBsRHTlkM9zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each graph in the dataset generated was ran through these 10 methods and an answer key was generated for each graph. This will allow us to score the LLM's performance based on the answers the LLM provides and comparing it with answers we know are correct. Each answer key was saved under the \"Graph Task QA\" column with its respective graph in a table."
      ],
      "metadata": {
        "id": "g7SNC65jNBSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bdXKg0EqQ93C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view the entire graph dataset that was generated for this project, visit this google sheets link: [CS 159 GRAPHS](https://docs.google.com/spreadsheets/d/1-CZxCLi6CPrx62JLAnIldtkV5SAFmuxRYouZTMTHwGw/edit?usp=sharing) under the \"Graphs\" tab. (Caltech User Access Only)"
      ],
      "metadata": {
        "id": "aRuxndmIOqQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting"
      ],
      "metadata": {
        "id": "PcpBsSDHPbay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before prompting the LLM can begin, Open AI must be set up. For this project, Chat GPT 3.5 was used."
      ],
      "metadata": {
        "id": "IyK_0DzNPd4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "openai_api_key = \"sk-proj-lSCioYakgvDfBqaNjQz3T3BlbkFJQ21XNjzP0PNRXLsJxPDw\"\n",
        "url = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {openai_api_key}\"\n",
        "}\n",
        "\n",
        "data = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What color are apples, in one word?\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers, json=data)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    print(\"Response from OpenAI:\", response.json())\n",
        "    print('\\n')\n",
        "    print(response.json()['choices'][0]['message']['content'])\n",
        "else:\n",
        "    print(\"Error:\", response.status_code, response.text)"
      ],
      "metadata": {
        "id": "XZXvesqXO6hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The different prompting methods utilized were: Zero-Shot, Few-Shot, Random-CoT, Matched-CoT, and Adjacency CoT. 10 graphs were randomly selected from the dataset and assigned to each prompting method, for a total of 50 graphs being assigned (there were some repeated graphs, and there were some graphs that were not used at all). Moreover, 1 graph was randomly selected from each encoding type to have a Chain-of-Thought explanation written for it, which was used by Random-CoT and Matched-CoT."
      ],
      "metadata": {
        "id": "cazw4XMYSKJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, prompting scripts had to be generated for each graph. We automated this process, to maintain consistency in the prompting texts and to save time. We made sure to match the prompt scripts with the specific values that each graph algorithm appended to \"answers\"."
      ],
      "metadata": {
        "id": "-pycDvaCP5Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_graph_output(names_index, output_template):\n",
        "    name_placeholders = {\n",
        "        \"[1st name]\": names_index[0],\n",
        "        \"[2nd name]\": names_index[1],\n",
        "        \"[3rd name]\": names_index[2],\n",
        "        \"[4th name]\": names_index[3]\n",
        "    }\n",
        "\n",
        "    for placeholder, name in name_placeholders.items():\n",
        "        output_template = output_template.replace(placeholder, name)\n",
        "\n",
        "    return output_template\n",
        "\n",
        "names_index = ['0', '1', '2', '3', '4']\n",
        "output_template = \"\"\"1. Edge existence. Determine whether an edge exists between [1st name] and [3rd name], for both directions. Output as \"1. (True/False, True/False)\"\n",
        "2. Node degree. Calculate the in degree and out degree of [4th name]. Output as “2. 123”\n",
        "3. Node count. Count the number of nodes in this graph. Output as “3. 123”\n",
        "4. Edge count. Count the number of edges in this graph. Output as “4. 123”\n",
        "5. Connected nodes. Find all the nodes that are connected to [3rd name] in this graph. Output as “5. 123”\n",
        "6. Cycle check. Determine whether this graph contains a cycle. Output as “6. (True/False)”\n",
        "7. Disconnected nodes. Find all the nodes that are not connected to [4th name] in this graph. Output as “7. 123”\n",
        "8. Reachability. Determine whether there is a path from [1st name] and [3rd name]. Output as “8. (True/False)”\n",
        "9. Shortest path. Calculate the length of the shortest path from [2nd name] and [4th name]. Output as “9. 123”\n",
        "10. Weakly Connected. Determine whether this graph is weakly connected. Output as “10. (True/False)”\n",
        "\"\"\"\n",
        "\n",
        "formatted_output = format_graph_output(names_index, output_template)\n",
        "print(formatted_output)"
      ],
      "metadata": {
        "id": "DajqrGBCQts3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each prompting script was saved with its respective graph under the \"Task Questions\" tab, which can be found [CS 159 GRAPHS](https://docs.google.com/spreadsheets/d/1-CZxCLi6CPrx62JLAnIldtkV5SAFmuxRYouZTMTHwGw/edit?usp=sharing) under the \"Numbered List\" page. (Caltech User Access Only)\n",
        "\n",
        "To see the prompting scripts used for each graph for all the prompting methods, visit the \"LLM Prompts\" page on the spreadsheet."
      ],
      "metadata": {
        "id": "Luwmn6x4Q4Cr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it is time to prompt the LLM! For each graph, the LLM was given the written prompts and the LLM's answers were saved to the spreadsheet's \"LLM Answers\" page. Read our final report to find further clarification, final results, and their implications for future research. Thanks!"
      ],
      "metadata": {
        "id": "JqnmZXICUIWg"
      }
    }
  ]
}